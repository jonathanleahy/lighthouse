[# Project Files Summary - Part 1

Generated on: 2024-12-21T21:12:46Z

Root Directory: ./server4

---

## Directory: .idea

## File: .idea/.gitignore

Size: 176 bytes

Last Modified: 2024-12-21T10:13:09Z

```
# Default ignored files
/shelf/
/workspace.xml
# Editor-based HTTP Client requests
/httpRequests/
# Datasource local storage ignored files
/dataSources/
/dataSources.local.xml

```

## File: .idea/modules.xml

Size: 266 bytes

Last Modified: 2024-12-21T10:13:07Z

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ProjectModuleManager">
    <modules>
      <module fileurl="file://$PROJECT_DIR$/.idea/server4.iml" filepath="$PROJECT_DIR$/.idea/server4.iml" />
    </modules>
  </component>
</project>
```

## File: .idea/server4.iml

Size: 322 bytes

Last Modified: 2024-12-21T10:13:07Z

```
<?xml version="1.0" encoding="UTF-8"?>
<module type="WEB_MODULE" version="4">
  <component name="Go" enabled="true" />
  <component name="NewModuleRootManager">
    <content url="file://$MODULE_DIR$" />
    <orderEntry type="inheritedJdk" />
    <orderEntry type="sourceFolder" forTests="false" />
  </component>
</module>
```

## File: .idea/vcs.xml

Size: 183 bytes

Last Modified: 2024-12-21T10:13:07Z

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="VcsDirectoryMappings">
    <mapping directory="$PROJECT_DIR$/.." vcs="Git" />
  </component>
</project>
```

## File: .idea/workspace.xml

Size: 4845 bytes

Last Modified: 2024-12-21T21:08:29Z

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="ALL" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="8c4ba807-6f4d-4f41-8ea1-15fd00764a18" name="Changes" comment="">
      <change beforePath="$PROJECT_DIR$/main.go" beforeDir="false" afterPath="$PROJECT_DIR$/main.go" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/types.go" beforeDir="false" afterPath="$PROJECT_DIR$/types.go" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/../server4_collated_part1.md" beforeDir="false" afterPath="$PROJECT_DIR$/../server4_collated_part1.md" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="GOROOT" url="file:///snap/go/current" />
  <component name="Git.Settings">
    <option name="RECENT_BRANCH_BY_REPOSITORY">
      <map>
        <entry key="$PROJECT_DIR$/.." value="ed65c8113b4ef228d5bb4a0df257c2c0c36c6e97" />
      </map>
    </option>
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$/.." />
    <option name="RESET_MODE" value="MIXED" />
  </component>
  <component name="GitHubPullRequestSearchHistory">{
  &quot;lastFilter&quot;: {
    &quot;state&quot;: &quot;OPEN&quot;,
    &quot;assignee&quot;: &quot;jonathanleahy&quot;
  }
}</component>
  <component name="GithubPullRequestsUISettings">{
  &quot;selectedUrlAndAccountId&quot;: {
    &quot;url&quot;: &quot;https://github.com/jonathanleahy/lighthouse.git&quot;,
    &quot;accountId&quot;: &quot;48ebb4ce-34fe-4984-a0aa-c40105418828&quot;
  }
}</component>
  <component name="NamedScopeManager">
    <scope name="GitScopePro" pattern="" />
  </component>
  <component name="ProjectColorInfo">{
  &quot;associatedIndex&quot;: 2
}</component>
  <component name="ProjectId" id="2qWQjDcLV5exLfoRlNFwYwPvIcw" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">{
  &quot;keyToString&quot;: {
    &quot;Go Build.go build server4.executor&quot;: &quot;Run&quot;,
    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.git.unshallow&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.go.formatter.settings.were.checked&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.go.migrated.go.modules.settings&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.go.modules.go.list.on.any.changes.was.set&quot;: &quot;true&quot;,
    &quot;git-widget-placeholder&quot;: &quot;main&quot;,
    &quot;go.import.settings.migrated&quot;: &quot;true&quot;,
    &quot;last_opened_file_path&quot;: &quot;/home/jon&quot;,
    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
    &quot;onboarding.tips.debug.path&quot;: &quot;/home/jon/lighthouse/server4/main.go&quot;
  }
}</component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="$PROJECT_DIR$" />
    </key>
  </component>
  <component name="RunManager">
    <configuration name="go build server4" type="GoApplicationRunConfiguration" factoryName="Go Application" nameIsGenerated="true">
      <module name="server4" />
      <working_directory value="$PROJECT_DIR$" />
      <kind value="PACKAGE" />
      <package value="server4" />
      <directory value="$PROJECT_DIR$" />
      <filePath value="$PROJECT_DIR$" />
      <method v="2" />
    </configuration>
  </component>
  <component name="SharedIndexes">
    <attachedChunks>
      <set>
        <option value="bundled-gosdk-d297c17c1fbd-b87a2f8923ed-org.jetbrains.plugins.go.sharedIndexes.bundled-GO-243.21565.208" />
        <option value="bundled-js-predefined-d6986cc7102b-e768b9ed790e-JavaScript-GO-243.21565.208" />
      </set>
    </attachedChunks>
  </component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State />
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="VgoProject">
    <settings-migrated>true</settings-migrated>
  </component>
</project>
```

## Directory: config

## File: config/service-config.json

Size: 2415 bytes

Last Modified: 2024-12-21T15:55:37Z

```json
{
  "version": "1.0",
  "system": {
    "serviceTypes": {
      "check": {
        "description": "Health and status checking workflow",
        "queues": ["service_checks", "performance_analysis", "ai_analysis"],
        "handlers": {
          "dns": {
            "name": "dnsHandler",
            "cacheSeconds": 60,
            "description": "Quick DNS resolution check, cache for 1 minute",
            "dependencies": []
          },
          "github": {
            "name": "githubHandler",
            "cacheSeconds": 86400,
            "description": "GitHub repo check, cache for 24 hours",
            "dependencies": ["dns"]
          },
          "performance": {
            "name": "performanceHandler",
            "cacheSeconds": 300,
            "description": "Performance metrics, cache for 5 minutes",
            "dependencies": ["github"]
          },
          "ai": {
            "name": "aiHandler",
            "cacheSeconds": 3600,
            "description": "AI analysis, cache for 1 hour",
            "dependencies": ["dns", "github", "performance"]
          }
        }
      },
      "report": {
        "description": "Detailed reporting workflow",
        "queues": ["data_collection", "metric_analysis", "report_generation"],
        "handlers": {
          "metrics": {
            "name": "metricCollector",
            "cacheSeconds": 300,
            "description": "Metric collection, cache for 5 minutes"
          },
          "logs": {
            "name": "logAnalyzer",
            "cacheSeconds": 600,
            "description": "Log analysis, cache for 10 minutes"
          },
          "trends": {
            "name": "trendAnalyzer",
            "cacheSeconds": 1800,
            "description": "Trend analysis, cache for 30 minutes"
          },
          "report": {
            "name": "reportGenerator",
            "cacheSeconds": 3600,
            "description": "Report generation, cache for 1 hour"
          }
        }
      }
    },
    "queues": [
      {
        "name": "service_checks",
        "type": "worker",
        "maxConcurrent": 2,
        "queueSize": 100
      },
      {
        "name": "performance_analysis",
        "type": "worker",
        "maxConcurrent": 3,
        "queueSize": 50
      },
      {
        "name": "ai_analysis",
        "type": "worker",
        "maxConcurrent": 1,
        "queueSize": 50
      }
    ]
  }
}
```

## File: go.mod

Size: 72 bytes

Last Modified: 2024-12-21T11:02:54Z

```
module server4

go 1.23

require github.com/rs/cors v1.11.1 // indirect

```

## File: go.sum

Size: 157 bytes

Last Modified: 2024-12-21T11:02:54Z

```
github.com/rs/cors v1.11.1 h1:eU3gRzXLRK57F5rKMGMZURNdIG4EoAmX8k94r9wXWHA=
github.com/rs/cors v1.11.1/go.mod h1:XyqrcTp5zjWr1wsJ8PIRZssZ8b/WMcMf71DJnit4EMU=

```

## File: handlers.go

Size: 1968 bytes

Last Modified: 2024-12-21T10:15:04Z

```go
package main

import (
	"fmt"
	"math/rand"
	"time"
)

type HandlerFunc func(ctx *Context) *Result

// HandlerRegistry contains all available handlers
var HandlerRegistry = map[string]HandlerFunc{
	// Check workflow handlers
	"dnsHandler": func(ctx *Context) *Result {
		return simulateWork("DNS Check", ctx, 1, 5)
	},
	"githubHandler": func(ctx *Context) *Result {
		return simulateWork("GitHub Check", ctx, 1, 5)
	},
	"performanceHandler": func(ctx *Context) *Result {
		return simulateWork("Performance Analysis", ctx, 2, 5)
	},
	"aiHandler": func(ctx *Context) *Result {
		return simulateWork("AI Analysis", ctx, 3, 5)
	},

	// Report workflow handlers
	"metricCollector": func(ctx *Context) *Result {
		return simulateWork("Metric Collection", ctx, 1, 4)
	},
	"logAnalyzer": func(ctx *Context) *Result {
		return simulateWork("Log Analysis", ctx, 2, 5)
	},
	"trendAnalyzer": func(ctx *Context) *Result {
		return simulateWork("Trend Analysis", ctx, 2, 4)
	},
	"reportGenerator": func(ctx *Context) *Result {
		return simulateWork("Report Generation", ctx, 3, 5)
	},
}

// simulateWork simulates processing with random delay and console output
func simulateWork(handlerName string, ctx *Context, minSec, maxSec int) *Result {
	start := time.Now()

	fmt.Printf("\n[%s] Starting %s for service '%s' (%s workflow)\n",
		start.Format("15:04:05"),
		handlerName,
		ctx.ServiceName,
		ctx.ProcessType)

	// Random delay between minSec and maxSec seconds
	delay := time.Duration(minSec+rand.Intn(maxSec-minSec+1)) * time.Second
	time.Sleep(delay)

	// Simulate occasional failures (10% chance)
	status := "completed"
	if rand.Float32() < 0.1 {
		status = "failed"
	}

	end := time.Now()

	fmt.Printf("[%s] %s %s for service '%s' after %v\n",
		end.Format("15:04:05"),
		status,
		handlerName,
		ctx.ServiceName,
		delay)

	return &Result{
		Status:    status,
		Message:   fmt.Sprintf("%s %s in %v", handlerName, status, delay),
		StartTime: start,
		EndTime:   end,
	}
}

```

## File: http_handlers.go

Size: 7343 bytes

Last Modified: 2024-12-21T15:21:01Z

```go
package main

import (
	"encoding/json"
	"fmt"
	"net/http"
	"strconv"
	"strings"
	"time"
)

func handleCheckRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req ServiceRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request body", http.StatusBadRequest)
		return
	}

	result, err := pm.HandleRequest(req)
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	// Log status
	switch status := result.(type) {
	case *QueueStatus:
		fmt.Printf("\n[%s] Service %s (%s): %s, Position: %d\n",
			time.Now().Format("15:04:05"),
			req.Name,
			req.Type,
			status.Status,
			status.Position)
		if len(status.StepsToRun) > 0 {
			fmt.Printf("Steps to run: %v\n", status.StepsToRun)
		}
	case *CachedResponse:
		fmt.Printf("\n[%s] Service %s (%s): Using cached results\n",
			time.Now().Format("15:04:05"),
			req.Name,
			req.Type)
	}

	json.NewEncoder(w).Encode(result)
}

func handleControlRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	command := ControlCommand(r.URL.Query().Get("command"))
	if command == "" {
		http.Error(w, "Command required", http.StatusBadRequest)
		return
	}

	state, err := pm.HandleControlCommand(command)
	if err != nil {
		http.Error(w, err.Error(), http.StatusBadRequest)
		return
	}

	json.NewEncoder(w).Encode(state)
}

func handleDebugRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	format := r.URL.Query().Get("format")
	debug := pm.GetSystemDebugInfo()

	if format == "text" {
		w.Header().Set("Content-Type", "text/plain")
		writeTextDebugInfo(w, debug)
	} else {
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(debug)
	}
}

func handleInvalidateRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	if r.Method != http.MethodPost {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	var req InvalidationRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		http.Error(w, "Invalid request body", http.StatusBadRequest)
		return
	}

	// Count of invalidated entries
	invalidated := 0

	// Handle wildcard service name
	if req.ServiceName == "*" {
		pm.mu.RLock()
		for cacheKey := range pm.cache {
			if req.Type == "*" || strings.HasSuffix(cacheKey, "-"+req.Type) {
				if err := pm.InvalidateCache(InvalidationRequest{
					ServiceName: strings.TrimSuffix(strings.TrimSuffix(cacheKey, "-"+req.Type), "-"),
					Type:        req.Type,
					Handlers:    req.Handlers,
					ResetTimes:  req.ResetTimes,
				}); err == nil {
					invalidated++
				}
			}
		}
		pm.mu.RUnlock()
	} else {
		// Handle single service invalidation
		if err := pm.InvalidateCache(req); err == nil {
			invalidated++
		}
	}

	json.NewEncoder(w).Encode(map[string]interface{}{
		"status":            "success",
		"invalidated_count": invalidated,
		"request":           req,
	})
}

func handleJobHistory(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	w.Header().Set("Content-Type", "application/json")

	// Get optional limit from query params
	limit := 1000
	if limitStr := r.URL.Query().Get("limit"); limitStr != "" {
		if l, err := strconv.Atoi(limitStr); err == nil && l > 0 {
			limit = l
		}
	}

	pm.history.mu.RLock()
	jobs := pm.history.CompletedJobs
	if len(jobs) > limit {
		jobs = jobs[len(jobs)-limit:]
	}
	pm.history.mu.RUnlock()

	json.NewEncoder(w).Encode(map[string]interface{}{
		"completed_jobs": jobs,
	})
}

func handleHealthRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	if r.Method != http.MethodGet {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	metrics := pm.GetSystemMetrics()

	// Determine health status
	status := "healthy"
	if metrics.SystemState.Status != "running" ||
		metrics.QueueStats.ActiveChecks > 2 ||
		metrics.QueueStats.QueueLength > int(float64(metrics.QueueStats.MaxQueueSize)*0.9) {
		status = "degraded"
	}

	// Prepare health response
	healthResponse := map[string]interface{}{
		"status":       status,
		"uptime":       time.Since(metrics.SystemState.LastUpdated).String(),
		"metrics":      metrics,
		"queue_status": metrics.QueueStats, // Include full queue stats
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(healthResponse)
}

func handleQueuedJobsRequest(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	if r.Method != http.MethodGet {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}

	// Get queue stats which include queued jobs
	queueStats := pm.GetQueueStats()

	response := map[string]interface{}{
		"queued_jobs":  queueStats.QueuedJobs,
		"total_queued": len(queueStats.QueuedJobs),
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(response)
}

// Ensure this method in http_handlers.go is working correctly
func handleJobProgress(w http.ResponseWriter, r *http.Request, pm *ProcessManager) {
	w.Header().Set("Content-Type", "application/json")

	// Get optional service name and type from query params
	serviceName := r.URL.Query().Get("service")
	serviceType := r.URL.Query().Get("type")

	// Get in-progress jobs
	activeJobs := make(map[string]*ServiceProgress)

	pm.mu.RLock()
	for key, progress := range pm.progress {
		if (serviceName == "" || progress.ServiceName == serviceName) &&
			(serviceType == "" || progress.Type == serviceType) {
			activeJobs[key] = progress
		}
	}
	pm.mu.RUnlock()

	json.NewEncoder(w).Encode(map[string]interface{}{
		"active_jobs": activeJobs,
	})
}

func writeTextDebugInfo(w http.ResponseWriter, debug SystemDebugInfo) {
	fmt.Fprintf(w, "=== System Debug Info ===\n")
	fmt.Fprintf(w, "Time: %s\n\n", debug.Timestamp.Format(time.RFC3339))

	fmt.Fprintf(w, "=== Queue Status ===\n")
	fmt.Fprintf(w, "Queue Length: %d/%d\n", debug.QueueStatus.QueueLength, debug.QueueStatus.MaxQueueSize)
	if len(debug.QueueStatus.QueuedItems) > 0 {
		fmt.Fprintf(w, "\nQueued Items:\n")
		for _, item := range debug.QueueStatus.QueuedItems {
			fmt.Fprintf(w, "- %s (%s)\n", item.ServiceName, item.Type)
			fmt.Fprintf(w, "  Position: %d, Wait Time: %s\n", item.Position, item.WaitTime)
			fmt.Fprintf(w, "  Steps to Run: %v\n", item.StepsToRun)
		}
	}

	fmt.Fprintf(w, "\n=== Cache Status ===\n")
	fmt.Fprintf(w, "Total Cached Services: %d\n", debug.CacheStatus.TotalEntries)
	for key, entry := range debug.CacheStatus.Entries {
		fmt.Fprintf(w, "\n%s:\n", key)
		for stepID, status := range entry.StepStatuses {
			fmt.Fprintf(w, "  %s: %s (Age: %s)\n", stepID, status.Status, status.Age)
			fmt.Fprintf(w, "    Expires: %s\n", status.CacheExpires.Format(time.RFC3339))
		}
	}

	fmt.Fprintf(w, "\n=== Processing Status ===\n")
	fmt.Fprintf(w, "Active Processes: %d\n", debug.ProcessStatus.ActiveProcesses)
	for key, item := range debug.ProcessStatus.ProcessingItems {
		fmt.Fprintf(w, "\n%s:\n", key)
		fmt.Fprintf(w, "  Running for: %s\n", item.ProcessTime)
		fmt.Fprintf(w, "  Completed Steps: %v\n", item.CompletedSteps)
		fmt.Fprintf(w, "  Pending Steps: %v\n", item.PendingSteps)
	}
}

```

## File: main.go

Size: 6686 bytes

Last Modified: 2024-12-21T15:51:26Z

```go
package main

import (
	"encoding/json"
	"fmt"
	"math/rand"
	"net/http"
	"os"
	"time"

	// Import the CORS middleware library
	"github.com/rs/cors"
)

func main() {
	// Seed random number generator for simulated work
	rand.Seed(time.Now().UnixNano())

	// Load configuration
	configFile, err := os.ReadFile("config/service-config.json")
	if err != nil {
		fmt.Printf("Error reading config: %v\n", err)
		os.Exit(1)
	}

	var config TreeConfig
	if err := json.Unmarshal(configFile, &config); err != nil {
		fmt.Printf("Error parsing config: %v\n", err)
		os.Exit(1)
	}

	// Initialize process manager
	processManager := NewProcessManager(config)

	// Start worker pool for processing queue
	for i := 0; i < 5; i++ {
		go func(id int) {
			for {
				processManager.processNextInQueue()
				time.Sleep(100 * time.Millisecond)
			}
		}(i)
	}

	// Setup HTTP handlers using the default mux
	http.HandleFunc("/check", func(w http.ResponseWriter, r *http.Request) {
		handleCheckRequest(w, r, processManager)
	})
	http.HandleFunc("/control", func(w http.ResponseWriter, r *http.Request) {
		handleControlRequest(w, r, processManager)
	})
	http.HandleFunc("/debug", func(w http.ResponseWriter, r *http.Request) {
		handleDebugRequest(w, r, processManager)
	})
	http.HandleFunc("/invalidate", func(w http.ResponseWriter, r *http.Request) {
		handleInvalidateRequest(w, r, processManager)
	})
	http.HandleFunc("/jobs/queue", func(w http.ResponseWriter, r *http.Request) {
		handleQueuedJobsRequest(w, r, processManager)
	})
	http.HandleFunc("/jobs/progress", func(w http.ResponseWriter, r *http.Request) {
		handleJobProgress(w, r, processManager)
	})
	http.HandleFunc("/jobs/history", func(w http.ResponseWriter, r *http.Request) {
		handleJobHistory(w, r, processManager)
	})

	// Add health check endpoint
	http.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
		handleHealthRequest(w, r, processManager)
	})

	// Add service types endpoint
	http.HandleFunc("/service-types", func(w http.ResponseWriter, r *http.Request) {
		if r.Method != http.MethodGet {
			http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
			return
		}

		// Extract service types from the configuration
		serviceTypes := make(map[string]interface{})
		for typeName, typeConfig := range config.System.ServiceTypes {
			serviceTypes[typeName] = map[string]interface{}{
				"description": typeConfig.Description,
				"queues":      typeConfig.Queues,
				"handlers":    typeConfig.Handlers,
			}
		}

		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(serviceTypes)
	})

	// Print startup information and usage instructions
	fmt.Printf("\n=== Service Processor Starting ===\n")
	fmt.Printf("Available Service Types:\n")
	for serviceType, svcConfig := range config.System.ServiceTypes {
		fmt.Printf("- %s: %s\n", serviceType, svcConfig.Description)
		fmt.Printf("  Handlers:\n")
		for handlerID, handler := range svcConfig.Handlers {
			fmt.Printf("    - %s: Cache time %ds\n", handlerID, handler.CacheSeconds)
		}
	}

	fmt.Printf("\nEndpoints:\n")
	fmt.Printf("\n1. Submit Service Check:\n")
	fmt.Printf("   curl -X POST http://localhost:8080/check \\\n")
	fmt.Printf("        -H \"Content-Type: application/json\" \\\n")
	fmt.Printf("        -d '{\"name\":\"payments\",\"type\":\"check\"}'\n")

	fmt.Printf("\n2. Control System:\n")
	fmt.Printf("   # Pause processing:\n")
	fmt.Printf("   curl -X POST \"http://localhost:8080/control?command=pause\"\n")
	fmt.Printf("   # Step through one operation:\n")
	fmt.Printf("   curl -X POST \"http://localhost:8080/control?command=step\"\n")
	fmt.Printf("   # Resume processing:\n")
	fmt.Printf("   curl -X POST \"http://localhost:8080/control?command=resume\"\n")
	fmt.Printf("   # Reset system:\n")
	fmt.Printf("   curl -X POST \"http://localhost:8080/control?command=reset\"\n")

	fmt.Printf("\n3. Debug Information:\n")
	fmt.Printf("   # Get human-readable status:\n")
	fmt.Printf("   curl \"http://localhost:8080/health?format=text\"\n")
	fmt.Printf("   # Get JSON status:\n")
	fmt.Printf("   curl http://localhost:8080/health\n")

	fmt.Printf("\n4. Cache Invalidation:\n")
	fmt.Printf("   # Invalidate specific service:\n")
	fmt.Printf("   curl -X POST http://localhost:8080/invalidate \\\n")
	fmt.Printf("        -H \"Content-Type: application/json\" \\\n")
	fmt.Printf("        -d '{\"service_name\":\"payments\",\"type\":\"check\"}'\n")
	fmt.Printf("   # Invalidate all services of type:\n")
	fmt.Printf("   curl -X POST http://localhost:8080/invalidate \\\n")
	fmt.Printf("        -H \"Content-Type: application/json\" \\\n")
	fmt.Printf("        -d '{\"service_name\":\"*\",\"type\":\"check\"}'\n")

	fmt.Printf("\n5. Job Status:\n")
	fmt.Printf("   # Get active jobs:\n")
	fmt.Printf("   curl http://localhost:8080/jobs/progress\n")
	fmt.Printf("   # Get job history:\n")
	fmt.Printf("   curl http://localhost:8080/jobs/history\n")
	fmt.Printf("   # Get filtered history:\n")
	fmt.Printf("   curl \"http://localhost:8080/jobs/history?limit=10\"\n")

	fmt.Printf("\nExample Workflow:\n")
	fmt.Printf("1. Submit a check\n")
	fmt.Printf("2. View progress with /jobs/progress\n")
	fmt.Printf("3. Check history with /jobs/history\n")
	fmt.Printf("4. View debug info to see queue status\n")
	fmt.Printf("5. Use control commands to manage processing\n")

	fmt.Printf("\nServer starting on :8080...\n")
	fmt.Printf("===================================\n\n")

	// Create a CORS handler that wraps the default mux
	c := cors.New(cors.Options{
		AllowedOrigins: []string{
			"http://localhost:3000",
			"http://127.0.0.1:3000",
			"http://192.168.3.130:3000",
		}, // Add all potential frontend origins
		AllowedMethods: []string{"GET", "POST", "OPTIONS", "PUT", "DELETE"},
		AllowedHeaders: []string{
			"Content-Type",
			"X-Requested-With",
			"Authorization",
			"Accept",
		},
		AllowCredentials: true,
		MaxAge:           86400, // Cache preflight request results for 24 hours
	})

	// Wrap the default mux with the CORS middleware
	handler := c.Handler(http.DefaultServeMux)

	// Start HTTP server
	if err := http.ListenAndServe(":8080", handler); err != nil {
		fmt.Printf("Server error: %v\n", err)
		os.Exit(1)
	}
}

// Helper function to respond with error
func respondWithError(w http.ResponseWriter, code int, message string) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(code)
	json.NewEncoder(w).Encode(map[string]string{
		"error": message,
	})
}

// Helper function to respond with JSON
func respondWithJSON(w http.ResponseWriter, code int, payload interface{}) {
	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(code)
	json.NewEncoder(w).Encode(payload)
}

```

## File: process_manager.go

Size: 19614 bytes

Last Modified: 2024-12-21T15:55:37Z

```go
package main

import (
	"fmt"
	"sort"
	"strings"
	"sync"
	"time"
)

// ProcessManager handles all service processing
type ProcessManager struct {
	config      TreeConfig
	queue       *WorkQueue
	cache       map[string]*ServiceCache
	progress    map[string]*ServiceProgress
	state       *SystemState
	controlChan chan ControlCommand
	history     *JobHistory
	mu          sync.RWMutex
	stateMu     sync.RWMutex
}

// WorkQueue manages the processing queue
type WorkQueue struct {
	items      []*QueuedCheck
	processing map[string]bool
	maxSize    int
	mu         sync.RWMutex
}

// JobHistory tracks completed jobs
type JobHistory struct {
	CompletedJobs []*JobResult
	MaxJobs       int
	mu            sync.RWMutex
}

// JobResult stores the complete result of a job
type JobResult struct {
	ServiceName string
	Type        string
	StartTime   time.Time
	EndTime     time.Time
	Duration    string
	Status      string
	Steps       map[string]*StepProgress
	TreeOutput  string
}

func NewProcessManager(config TreeConfig) *ProcessManager {
	return &ProcessManager{
		config:   config,
		queue:    NewWorkQueue(100),
		cache:    make(map[string]*ServiceCache),
		progress: make(map[string]*ServiceProgress),
		state: &SystemState{
			Status:      "running",
			LastUpdated: time.Now(),
			StepMode:    false,
		},
		controlChan: make(chan ControlCommand, 10),
		history: &JobHistory{
			CompletedJobs: make([]*JobResult, 0),
			MaxJobs:       1000,
		},
	}
}

func NewWorkQueue(maxSize int) *WorkQueue {
	return &WorkQueue{
		items:      make([]*QueuedCheck, 0),
		processing: make(map[string]bool),
		maxSize:    maxSize,
	}
}

// HandleRequest processes new service check requests
func (pm *ProcessManager) HandleRequest(req ServiceRequest) (ServiceResponse, error) {
	cacheKey := pm.getCacheKey(req.Name, req.Type)

	// Check if already processing
	pm.queue.mu.RLock()
	if pm.queue.processing[cacheKey] {
		pos := pm.getQueuePosition(cacheKey)
		pm.queue.mu.RUnlock()
		return &QueueStatus{
			Status:    "processing",
			Position:  pos,
			CacheKey:  cacheKey,
			StartTime: time.Now(),
		}, nil
	}
	pm.queue.mu.RUnlock()

	// Initialize or get cache entry
	pm.mu.Lock()
	serviceCache, exists := pm.cache[cacheKey]
	if !exists {
		serviceCache = &ServiceCache{
			ServiceName: req.Name,
			Type:        req.Type,
			Steps:       make(map[string]StepCache),
			LastUpdated: time.Now(),
		}
		pm.cache[cacheKey] = serviceCache
	}
	pm.mu.Unlock()

	// Check which steps need processing
	expiredSteps := pm.identifyExpiredSteps(req.Type, serviceCache)

	// If no steps need processing, return cached results
	if len(expiredSteps) == 0 {
		return pm.getCachedResults(serviceCache), nil
	}

	// Add to queue if steps need processing
	return pm.queueRequest(req, expiredSteps, cacheKey)
}

// processNextInQueue processes the next item in the queue
// processNextInQueue processes the next item in the queue
func (pm *ProcessManager) processNextInQueue() {
	pm.queue.mu.Lock()

	// Log total queue items before processing
	fmt.Printf("\n[%s] Queue Processing - Total Items: %d\n",
		time.Now().Format("15:04:05"),
		len(pm.queue.items))

	// Check if queue is empty or processing limit is reached
	if len(pm.queue.items) == 0 {
		pm.queue.mu.Unlock()
		return
	}

	// Determine max concurrent jobs from configuration
	var maxConcurrent int
	for _, queueConfig := range pm.config.System.Queues {
		if queueConfig.Name == "service_checks" {
			maxConcurrent = queueConfig.MaxConcurrent
			break
		}
	}

	// Log current processing state
	fmt.Printf("Current Processing Status:\n")
	fmt.Printf("Max Concurrent Jobs: %d\n", maxConcurrent)
	fmt.Printf("Active Checks: %d\n", len(pm.queue.processing))

	// If processing limit is reached, do not process more jobs
	if len(pm.queue.processing) >= maxConcurrent {
		fmt.Printf("Processing limit reached. Skipping job processing.\n")
		pm.queue.mu.Unlock()
		return
	}

	// Get next check from queue
	check := pm.queue.items[0]
	pm.queue.items = pm.queue.items[1:]

	// Mark as processing
	cacheKey := pm.getCacheKey(check.ServiceName, check.Type)
	pm.queue.processing[cacheKey] = true

	// Update positions for remaining items
	for i, item := range pm.queue.items {
		item.Position = i + 1
	}
	pm.queue.mu.Unlock()

	// Log job being processed
	fmt.Printf("[%s] Processing Job: %s (%s)\n",
		time.Now().Format("15:04:05"),
		check.ServiceName,
		check.Type)

	// Process the check
	go func() {
		defer func() {
			pm.queue.mu.Lock()
			delete(pm.queue.processing, cacheKey)
			pm.queue.mu.Unlock()
		}()

		pm.processCheck(check)
	}()
}
func (pm *ProcessManager) processCheck(check *QueuedCheck) {
	if check == nil {
		fmt.Printf("\n[%s] Error: nil check received\n", time.Now().Format("15:04:05"))
		return
	}

	progress := pm.getOrCreateProgress(ServiceRequest{
		Name: check.ServiceName,
		Type: check.Type,
	})

	if progress == nil {
		fmt.Printf("\n[%s] Error: could not create progress tracker for %s\n",
			time.Now().Format("15:04:05"), check.ServiceName)
		return
	}

	progress.mu.Lock()
	progress.Status = "processing"
	progress.StartTime = time.Now()
	progress.mu.Unlock()

	defer func() {
		if r := recover(); r != nil {
			fmt.Printf("\n[%s] Recovered from panic in processCheck: %v\n",
				time.Now().Format("15:04:05"), r)

			progress.mu.Lock()
			progress.Status = "failed"
			progress.LastUpdated = time.Now()
			progress.mu.Unlock()
		}
	}()

	// Identify steps to run with dependencies
	serviceType, exists := pm.config.System.ServiceTypes[progress.Type]
	if !exists {
		fmt.Printf("\n[%s] Error: service type %s not found\n",
			time.Now().Format("15:04:05"), progress.Type)
		return
	}

	// Determine which steps can be run based on dependencies
	for _, stepID := range check.StepsToRun {
		pm.stateMu.RLock()
		currentState := pm.state.Status
		stepMode := pm.state.StepMode
		pm.stateMu.RUnlock()

		if currentState == "paused" && !stepMode {
			fmt.Printf("\n[%s] Processing paused before step: %s\n",
				time.Now().Format("15:04:05"), stepID)
			return
		}

		// Check handler configuration and dependencies
		handlerConfig, exists := serviceType.Handlers[stepID]
		if !exists {
			fmt.Printf("\n[%s] No handler found for step: %s\n",
				time.Now().Format("15:04:05"), stepID)
			progress.mu.Lock()
			if progress.Steps[stepID] != nil {
				progress.Steps[stepID].Status = "failed"
				progress.Steps[stepID].Result = &Result{
					Status:  "error",
					Message: fmt.Sprintf("No handler found for step %s", stepID),
				}
			}
			progress.mu.Unlock()
			continue
		}

		// Check if all dependencies are completed successfully
		dependenciesMet := true
		for _, depStep := range handlerConfig.Dependencies {
			progress.mu.RLock()
			depStepProgress, exists := progress.Steps[depStep]
			progress.mu.RUnlock()

			if !exists || depStepProgress.Status != "completed" {
				dependenciesMet = false
				fmt.Printf("\n[%s] Dependencies not met for step: %s\n",
					time.Now().Format("15:04:05"), stepID)
				break
			}
		}

		// Skip if dependencies are not met
		if !dependenciesMet {
			continue
		}

		// Update current step in system state
		pm.stateMu.Lock()
		pm.state.CurrentStep = stepID
		pm.state.LastUpdated = time.Now()
		pm.stateMu.Unlock()

		// Execute the handler
		ctx := &Context{
			ServiceName: progress.ServiceName,
			ProcessType: progress.Type,
			StepID:      stepID,
		}

		result := HandlerRegistry[handlerConfig.Name](ctx)

		// Update progress
		progress.mu.Lock()
		if progress.Steps[stepID] != nil {
			progress.Steps[stepID].Status = "completed"
			progress.Steps[stepID].Result = result
			progress.Steps[stepID].EndTime = time.Now()
			progress.Steps[stepID].LastUpdated = time.Now()
		}
		progress.CompletedSteps++
		progress.mu.Unlock()

		// Handle step mode
		if stepMode {
			select {
			case cmd := <-pm.controlChan:
				if cmd != CommandStep {
					return
				}
			case <-time.After(time.Second * 30):
				fmt.Printf("\n[%s] Step timeout for: %s\n",
					time.Now().Format("15:04:05"), stepID)
				return
			}
		}
	}

	// Update final status
	progress.mu.Lock()
	progress.Status = "completed"
	progress.LastUpdated = time.Now()
	progress.mu.Unlock()

	// Generate tree output and save history
	treeOutput := pm.generateTreeOutput(progress)
	if treeOutput != "" {
		result := &JobResult{
			ServiceName: progress.ServiceName,
			Type:        progress.Type,
			StartTime:   progress.StartTime,
			EndTime:     progress.LastUpdated,
			Duration:    progress.LastUpdated.Sub(progress.StartTime).String(),
			Status:      progress.Status,
			Steps:       progress.Steps,
			TreeOutput:  treeOutput,
		}

		// Save to history
		pm.history.mu.Lock()
		pm.history.CompletedJobs = append(pm.history.CompletedJobs, result)
		if len(pm.history.CompletedJobs) > pm.history.MaxJobs {
			pm.history.CompletedJobs = pm.history.CompletedJobs[1:]
		}
		pm.history.mu.Unlock()

		// Print tree output
		fmt.Printf("\n%s\n", treeOutput)
	}

	// Update cache
	cacheKey := pm.getCacheKey(progress.ServiceName, progress.Type)
	pm.mu.Lock()
	if serviceCache, exists := pm.cache[cacheKey]; exists {
		serviceCache.mu.Lock()
		for stepID, step := range progress.Steps {
			if step.Result != nil {
				serviceCache.Steps[stepID] = StepCache{
					Result:      step.Result,
					LastUpdated: time.Now(),
				}
			}
		}
		serviceCache.LastUpdated = time.Now()
		serviceCache.mu.Unlock()
	}
	pm.mu.Unlock()
}

// generateTreeOutput creates a tree visualization of the job
func (pm *ProcessManager) generateTreeOutput(progress *ServiceProgress) string {
	if progress == nil {
		return ""
	}

	var builder strings.Builder

	builder.WriteString(fmt.Sprintf("Service: %s (%s)\n", progress.ServiceName, progress.Type))
	builder.WriteString(fmt.Sprintf("├── Status: %s\n", progress.Status))
	builder.WriteString(fmt.Sprintf("├── Duration: %s\n", progress.LastUpdated.Sub(progress.StartTime)))
	builder.WriteString("└── Steps:\n")

	// Sort steps for consistent output
	stepIDs := make([]string, 0, len(progress.Steps))
	for stepID := range progress.Steps {
		stepIDs = append(stepIDs, stepID)
	}
	sort.Strings(stepIDs)

	for i, stepID := range stepIDs {
		step := progress.Steps[stepID]
		prefix := "    ├──"
		if i == len(stepIDs)-1 {
			prefix = "    └──"
		}

		builder.WriteString(fmt.Sprintf("%s %s\n", prefix, stepID))
		childPrefix := "    │   "
		if i == len(stepIDs)-1 {
			childPrefix = "        "
		}

		builder.WriteString(fmt.Sprintf("%s├── Status: %s\n", childPrefix, step.Status))
		if step.StartTime.IsZero() {
			builder.WriteString(fmt.Sprintf("%s└── Duration: Not started\n", childPrefix))
		} else if step.EndTime.IsZero() {
			builder.WriteString(fmt.Sprintf("%s└── Duration: In progress\n", childPrefix))
		} else {
			builder.WriteString(fmt.Sprintf("%s└── Duration: %s\n", childPrefix, step.EndTime.Sub(step.StartTime)))
		}
	}

	return builder.String()
}

// HandleControlCommand processes system control commands
func (pm *ProcessManager) HandleControlCommand(cmd ControlCommand) (*SystemState, error) {
	pm.stateMu.Lock()
	defer pm.stateMu.Unlock()

	switch cmd {
	case CommandPause:
		if pm.state.Status == "paused" {
			return pm.state, fmt.Errorf("system already paused")
		}
		pm.state.Status = "paused"
		pm.state.PausedAt = time.Now()
		pm.state.Message = "System paused"

	case CommandResume:
		if pm.state.Status == "running" {
			return pm.state, fmt.Errorf("system already running")
		}
		pm.state.Status = "running"
		pm.state.StepMode = false
		pm.state.Message = "System resumed"

	case CommandStep:
		if pm.state.Status != "paused" {
			return pm.state, fmt.Errorf("system must be paused to step")
		}
		pm.state.StepMode = true
		pm.state.Status = "stepping"
		pm.state.Message = "Executing one step"

		go func() {
			pm.controlChan <- CommandStep
		}()

	case CommandReset:
		pm.state.Status = "running"
		pm.state.StepMode = false
		pm.state.CurrentStep = ""
		pm.state.PendingSteps = nil
		pm.state.Message = "System reset"
	}

	pm.state.LastUpdated = time.Now()
	return pm.state, nil
}

// InvalidateCache handles cache invalidation requests
func (pm *ProcessManager) InvalidateCache(req InvalidationRequest) error {
	if req.ServiceName == "*" {
		pm.mu.Lock()
		for cacheKey, cache := range pm.cache {
			if req.Type == "*" || strings.HasSuffix(cacheKey, "-"+req.Type) {
				cache.mu.Lock()
				if len(req.Handlers) > 0 {
					for _, handlerID := range req.Handlers {
						delete(cache.Steps, handlerID)
					}
				} else {
					cache.Steps = make(map[string]StepCache)
				}
				if req.ResetTimes {
					cache.LastUpdated = time.Time{}
				}
				cache.mu.Unlock()
			}
		}
		pm.mu.Unlock()
		return nil
	}

	cacheKey := pm.getCacheKey(req.ServiceName, req.Type)
	pm.mu.Lock()
	cache, exists := pm.cache[cacheKey]
	pm.mu.Unlock()

	if !exists {
		return fmt.Errorf("no cache found for service %s (%s)", req.ServiceName, req.Type)
	}

	cache.mu.Lock()
	defer cache.mu.Unlock()

	if len(req.Handlers) > 0 {
		for _, handlerID := range req.Handlers {
			delete(cache.Steps, handlerID)
		}
	} else {
		cache.Steps = make(map[string]StepCache)
	}

	if req.ResetTimes {
		cache.LastUpdated = time.Time{}
	}

	return nil
}

// GetSystemDebugInfo returns comprehensive system debug information
func (pm *ProcessManager) GetSystemDebugInfo() SystemDebugInfo {
	debug := SystemDebugInfo{
		Timestamp: time.Now(),
		QueueStatus: QueueDebugInfo{
			QueuedItems: make([]QueuedItem, 0),
		},
		CacheStatus: CacheDebugInfo{
			Entries: make(map[string]CacheEntry),
		},
		ProcessStatus: ProcessDebugInfo{
			ProcessingItems: make(map[string]ProcessingItem),
		},
	}

	// Queue Status
	pm.queue.mu.RLock()
	debug.QueueStatus.QueueLength = len(pm.queue.items)
	debug.QueueStatus.MaxQueueSize = pm.queue.maxSize

	for _, item := range pm.queue.items {
		debug.QueueStatus.QueuedItems = append(debug.QueueStatus.QueuedItems, QueuedItem{
			ServiceName: item.ServiceName,
			Type:        item.Type,
			Position:    item.Position,
			QueueTime:   item.QueueTime,
			WaitTime:    time.Since(item.QueueTime).String(),
			StepsToRun:  item.StepsToRun,
		})
	}
	pm.queue.mu.RUnlock()

	// Cache Status
	pm.mu.RLock()
	debug.CacheStatus.TotalEntries = len(pm.cache)
	for key, cache := range pm.cache {
		cache.mu.RLock()
		entry := CacheEntry{
			ServiceName:  cache.ServiceName,
			Type:         cache.Type,
			LastUpdated:  cache.LastUpdated,
			StepStatuses: make(map[string]StepStatus),
		}

		if serviceType, exists := pm.config.System.ServiceTypes[cache.Type]; exists {
			for stepID, stepCache := range cache.Steps {
				if handlerConfig, exists := serviceType.Handlers[stepID]; exists {
					cacheExpiry := stepCache.LastUpdated.Add(time.Duration(handlerConfig.CacheSeconds) * time.Second)
					status := "valid"
					if time.Now().After(cacheExpiry) {
						status = "expired"
					}

					entry.StepStatuses[stepID] = StepStatus{
						Status:       status,
						LastUpdated:  stepCache.LastUpdated,
						CacheExpires: cacheExpiry,
						Age:          time.Since(stepCache.LastUpdated).String(),
					}
				}
			}
		}
		cache.mu.RUnlock()
		debug.CacheStatus.Entries[key] = entry
	}
	pm.mu.RUnlock()

	// Process Status
	pm.mu.RLock()
	debug.ProcessStatus.ActiveProcesses = len(pm.progress)
	for key, progress := range pm.progress {
		progress.mu.RLock()
		if progress.Status == "processing" || progress.Status == "initializing" {
			var completedSteps, pendingSteps []string
			for stepID, step := range progress.Steps {
				if step.Status == "completed" {
					completedSteps = append(completedSteps, stepID)
				} else if step.Status == "pending" || step.Status == "processing" {
					pendingSteps = append(pendingSteps, stepID)
				}
			}

			debug.ProcessStatus.ProcessingItems[key] = ProcessingItem{
				ServiceName:    progress.ServiceName,
				Type:           progress.Type,
				StartTime:      progress.StartTime,
				ProcessTime:    time.Since(progress.StartTime).String(),
				CompletedSteps: completedSteps,
				PendingSteps:   pendingSteps,
				TotalSteps:     progress.TotalSteps,
			}
		}
		progress.mu.RUnlock()
	}
	pm.mu.RUnlock()

	return debug
}

// GetQueueStatus returns current queue statistics
func (pm *ProcessManager) GetQueueStats() QueueStats {
	pm.queue.mu.RLock()
	defer pm.queue.mu.RUnlock()

	// Log detailed queue information
	fmt.Printf("\n[%s] Queue Statistics:\n", time.Now().Format("15:04:05"))
	fmt.Printf("Total Queue Items: %d\n", len(pm.queue.items))
	fmt.Printf("Active Processing: %d\n", len(pm.queue.processing))

	stats := QueueStats{
		QueueLength:    len(pm.queue.items),
		MaxQueueSize:   pm.queue.maxSize,
		ActiveChecks:   len(pm.queue.processing),
		QueuedServices: make([]string, 0),
		QueuedJobs:     make([]QueuedJobInfo, 0),
	}

	// Log each queued item
	for i, item := range pm.queue.items {
		queuedService := fmt.Sprintf("%s (%s)", item.ServiceName, item.Type)
		stats.QueuedServices = append(stats.QueuedServices, queuedService)

		queuedJob := QueuedJobInfo{
			ServiceName:   item.ServiceName,
			Type:          item.Type,
			QueuePosition: i + 1,
			QueueTime:     item.QueueTime,
			WaitTime:      time.Since(item.QueueTime).String(),
			StepsToRun:    item.StepsToRun,
		}
		stats.QueuedJobs = append(stats.QueuedJobs, queuedJob)

		fmt.Printf("Queued Job %d: %s (%s), Position: %d, Queued At: %s\n",
			i+1,
			item.ServiceName,
			item.Type,
			i+1,
			item.QueueTime.Format(time.RFC3339))
	}

	return stats
}

// Utility methods
func (pm *ProcessManager) getCacheKey(serviceName, processType string) string {
	return fmt.Sprintf("%s-%s", serviceName, processType)
}

func (pm *ProcessManager) getQueuePosition(cacheKey string) int {
	pm.queue.mu.RLock()
	defer pm.queue.mu.RUnlock()

	for i, check := range pm.queue.items {
		if pm.getCacheKey(check.ServiceName, check.Type) == cacheKey {
			return i + 1
		}
	}
	return 0
}

func (pm *ProcessManager) getHandlerConfig(serviceType, handlerID string) *HandlerConfig {
	if svcType, exists := pm.config.System.ServiceTypes[serviceType]; exists {
		if handler, exists := svcType.Handlers[handlerID]; exists {
			return &handler
		}
	}
	return nil
}

func (pm *ProcessManager) getOrCreateProgress(req ServiceRequest) *ServiceProgress {
	pm.mu.Lock()
	defer pm.mu.Unlock()

	cacheKey := pm.getCacheKey(req.Name, req.Type)
	if progress, exists := pm.progress[cacheKey]; exists {
		return progress
	}

	progress := &ServiceProgress{
		ServiceName: req.Name,
		Type:        req.Type,
		Status:      "initializing",
		Steps:       make(map[string]*StepProgress),
		StartTime:   time.Now(),
		LastUpdated: time.Now(),
	}

	// Initialize steps based on service type
	if serviceType, exists := pm.config.System.ServiceTypes[req.Type]; exists {
		progress.TotalSteps = len(serviceType.Handlers)
		for stepID := range serviceType.Handlers {
			progress.Steps[stepID] = &StepProgress{
				Status: "pending",
			}
		}
	}

	pm.progress[cacheKey] = progress
	return progress
}

// StartCleanupTask starts a periodic cleanup of old progress entries
func (pm *ProcessManager) StartCleanupTask(interval, maxAge time.Duration) {
	go func() {
		ticker := time.NewTicker(interval)
		for range ticker.C {
			pm.CleanupOldProgress(maxAge)
		}
	}()
}

// CleanupOldProgress removes completed progress entries older than the specified duration
func (pm *ProcessManager) CleanupOldProgress(maxAge time.Duration) {
	pm.mu.Lock()
	defer pm.mu.Unlock()

	now := time.Now()
	for key, progress := range pm.progress {
		progress.mu.RLock()
		if progress.Status == "completed" && now.Sub(progress.LastUpdated) > maxAge {
			delete(pm.progress, key)
		}
		progress.mu.RUnlock()
	}
}

```

## File: types.go

Size: 10594 bytes

Last Modified: 2024-12-21T21:09:03Z

```go
package main

import (
	"fmt"
	"sync"
	"time"
)

type ServiceType struct {
	Description string                   `json:"description"`
	Queues      []string                 `json:"queues"`
	Handlers    map[string]HandlerConfig `json:"handlers"`
}

type QueueConfig struct {
	Name          string `json:"name"`
	Type          string `json:"type"`
	MaxConcurrent int    `json:"maxConcurrent"`
	QueueSize     int    `json:"queueSize"`
}

type SystemConfig struct {
	ServiceTypes map[string]ServiceType `json:"serviceTypes"`
	Queues       []QueueConfig          `json:"queues"`
}

type TreeConfig struct {
	Version string       `json:"version"`
	System  SystemConfig `json:"system"`
}

// Runtime Types
type Context struct {
	ServiceName string
	ServiceURL  string
	ProcessType string
	StepID      string
}

type Result struct {
	Status    string      `json:"status"`
	Message   string      `json:"message"`
	Data      interface{} `json:"data,omitempty"`
	StartTime time.Time   `json:"start_time"`
	EndTime   time.Time   `json:"end_time"`
}

type StepProgress struct {
	Status      string    `json:"status"`
	LastUpdated time.Time `json:"last_updated,omitempty"`
	Result      *Result   `json:"result,omitempty"`
	StartTime   time.Time `json:"start_time,omitempty"`
	EndTime     time.Time `json:"end_time,omitempty"`
}

type ServiceProgress struct {
	ServiceName    string                   `json:"service_name"`
	Type           string                   `json:"type"`
	Status         string                   `json:"status"`
	QueuePosition  int                      `json:"queue_position,omitempty"`
	TotalSteps     int                      `json:"total_steps"`
	CompletedSteps int                      `json:"completed_steps"`
	Steps          map[string]*StepProgress `json:"steps"`
	StartTime      time.Time                `json:"start_time"`
	LastUpdated    time.Time                `json:"last_updated"`
	mu             sync.RWMutex
}

// Cache Types
type StepCache struct {
	Result      *Result   `json:"result"`
	LastUpdated time.Time `json:"last_updated"`
}

type ServiceCache struct {
	ServiceName string               `json:"service_name"`
	Type        string               `json:"type"`
	Steps       map[string]StepCache `json:"steps"`
	LastUpdated time.Time            `json:"last_updated"`
	mu          sync.RWMutex         // Add this mutex for thread-safe access
}

// Queue Types
type QueuedCheck struct {
	ServiceName string    `json:"service_name"`
	Type        string    `json:"type"`
	StepsToRun  []string  `json:"steps_to_run"`
	QueueTime   time.Time `json:"queue_time"`
	Position    int       `json:"position"`
}

// System State Types
type SystemState struct {
	Status       string    `json:"status"`
	LastUpdated  time.Time `json:"last_updated"`
	PausedAt     time.Time `json:"paused_at,omitempty"`
	StepMode     bool      `json:"step_mode"`
	CurrentStep  string    `json:"current_step,omitempty"`
	PendingSteps []string  `json:"pending_steps,omitempty"`
	Message      string    `json:"message,omitempty"`
}

type ControlCommand string

const (
	CommandPause  ControlCommand = "pause"
	CommandResume ControlCommand = "resume"
	CommandStep   ControlCommand = "step"
	CommandReset  ControlCommand = "reset"
)

// Request/Response Types
type ServiceRequest struct {
	Name     string `json:"name"`
	Type     string `json:"type"`
	URL      string `json:"url"`
	Priority int    `json:"priority"`
}

type InvalidationRequest struct {
	ServiceName string   `json:"service_name"`
	Type        string   `json:"type"`
	Handlers    []string `json:"handlers,omitempty"`
	ResetTimes  bool     `json:"reset_times"`
}

// Debug Types
type SystemDebugInfo struct {
	Timestamp     time.Time        `json:"timestamp"`
	QueueStatus   QueueDebugInfo   `json:"queue_status"`
	CacheStatus   CacheDebugInfo   `json:"cache_status"`
	ProcessStatus ProcessDebugInfo `json:"process_status"`
}

type QueueDebugInfo struct {
	QueueLength  int          `json:"queue_length"`
	MaxQueueSize int          `json:"max_queue_size"`
	QueuedItems  []QueuedItem `json:"queued_items"`
}

type QueuedItem struct {
	ServiceName string    `json:"service_name"`
	Type        string    `json:"type"`
	Position    int       `json:"position"`
	QueueTime   time.Time `json:"queue_time"`
	WaitTime    string    `json:"wait_time"`
	StepsToRun  []string  `json:"steps_to_run"`
}

type CacheDebugInfo struct {
	TotalEntries int                   `json:"total_entries"`
	Entries      map[string]CacheEntry `json:"entries"`
}

type CacheEntry struct {
	ServiceName  string                `json:"service_name"`
	Type         string                `json:"type"`
	LastUpdated  time.Time             `json:"last_updated"`
	StepStatuses map[string]StepStatus `json:"step_statuses"`
}

type StepStatus struct {
	Status       string    `json:"status"`
	LastUpdated  time.Time `json:"last_updated"`
	CacheExpires time.Time `json:"cache_expires"`
	Age          string    `json:"age"`
}

type ProcessDebugInfo struct {
	ActiveProcesses int                       `json:"active_processes"`
	ProcessingItems map[string]ProcessingItem `json:"processing_items"`
}

type ProcessingItem struct {
	ServiceName    string    `json:"service_name"`
	Type           string    `json:"type"`
	StartTime      time.Time `json:"start_time"`
	ProcessTime    string    `json:"process_time"`
	CompletedSteps []string  `json:"completed_steps"`
	PendingSteps   []string  `json:"pending_steps"`
	TotalSteps     int       `json:"total_steps"`
}

// SystemMetrics represents system-wide metrics
type SystemMetrics struct {
	TotalCacheEntries int         `json:"total_cache_entries"`
	ActiveProcesses   int         `json:"active_processes"`
	QueueStats        QueueStats  `json:"queue_stats"`
	SystemState       SystemState `json:"system_state"`
}

type QueueStats struct {
	QueueLength    int             `json:"queue_length"`
	MaxQueueSize   int             `json:"max_queue_size"`
	ActiveChecks   int             `json:"active_checks"`
	QueuedServices []string        `json:"queued_services"`
	QueuedJobs     []QueuedJobInfo `json:"queued_jobs"`
}

type QueuedJobInfo struct {
	ServiceName   string    `json:"service_name"`
	Type          string    `json:"type"`
	QueuePosition int       `json:"queue_position"`
	QueueTime     time.Time `json:"queue_time"`
	WaitTime      string    `json:"wait_time"`
	StepsToRun    []string  `json:"steps_to_run"`
}

type HandlerConfig struct {
	Name         string   `json:"name"`
	CacheSeconds int      `json:"cacheSeconds"`
	Description  string   `json:"description"`
	Dependencies []string `json:"dependencies,omitempty"`
}

type QueueStatus struct {
	Status     string    `json:"status"`
	Position   int       `json:"position"`
	CacheKey   string    `json:"cache_key"`
	QueueTime  time.Time `json:"queue_time"`
	StartTime  time.Time `json:"start_time"` // Add this line
	StepsToRun []string  `json:"steps_to_run,omitempty"`
}

type CachedResponse struct {
	Status     string                `json:"status"`
	LastUpdate time.Time             `json:"last_update"`
	Steps      map[string]StepResult `json:"steps"`
}

type StepResult struct {
	Status     string    `json:"status"`
	LastUpdate time.Time `json:"last_update"`
	Result     *Result   `json:"result,omitempty"`
}

// ServiceResponse is an interface that can be implemented by different response types
type ServiceResponse interface {
	ResponseType() string
}

// Ensure QueueStatus implements ServiceResponse
func (qs *QueueStatus) ResponseType() string {
	return qs.Status
}

// Ensure CachedResponse implements ServiceResponse
func (cr *CachedResponse) ResponseType() string {
	return "cached"
}

// identifyExpiredSteps checks which steps need to be reprocessed
func (pm *ProcessManager) identifyExpiredSteps(serviceType string, cache *ServiceCache) []string {
	var expiredSteps []string

	// Find the service type configuration
	svcType, exists := pm.config.System.ServiceTypes[serviceType]
	if !exists {
		return expiredSteps
	}

	cache.mu.RLock()
	defer cache.mu.RUnlock()

	// Check each handler for expiration
	for handlerID, handler := range svcType.Handlers {
		stepCache, exists := cache.Steps[handlerID]
		if !exists || time.Since(stepCache.LastUpdated) > time.Duration(handler.CacheSeconds)*time.Second {
			expiredSteps = append(expiredSteps, handlerID)
		}
	}

	return expiredSteps
}

// queueRequest adds a request to the processing queue
func (pm *ProcessManager) queueRequest(req ServiceRequest, expiredSteps []string, cacheKey string) (ServiceResponse, error) {
	pm.queue.mu.Lock()
	defer pm.queue.mu.Unlock()

	// Check if already in queue
	for _, check := range pm.queue.items {
		if check.ServiceName == req.Name && check.Type == req.Type {
			return &QueueStatus{
				Status:    "queued",
				Position:  check.Position,
				CacheKey:  cacheKey,
				QueueTime: check.QueueTime,
			}, nil
		}
	}

	// Add to queue if not full
	if len(pm.queue.items) >= pm.queue.maxSize {
		return nil, fmt.Errorf("queue is full")
	}

	queuedCheck := &QueuedCheck{
		ServiceName: req.Name,
		Type:        req.Type,
		StepsToRun:  expiredSteps,
		QueueTime:   time.Now(),
		Position:    len(pm.queue.items) + 1,
	}
	pm.queue.items = append(pm.queue.items, queuedCheck)

	return &QueueStatus{
		Status:     "queued",
		Position:   queuedCheck.Position,
		CacheKey:   cacheKey,
		QueueTime:  queuedCheck.QueueTime,
		StepsToRun: expiredSteps,
	}, nil
}

// getCachedResults is an internal method to get cached results for a service cache
func (pm *ProcessManager) getCachedResults(cache *ServiceCache) *CachedResponse {
	cache.mu.RLock()
	defer cache.mu.RUnlock()

	response := &CachedResponse{
		Status:     "cached",
		LastUpdate: cache.LastUpdated,
		Steps:      make(map[string]StepResult),
	}

	for stepID, stepCache := range cache.Steps {
		response.Steps[stepID] = StepResult{
			Status:     "cached",
			LastUpdate: stepCache.LastUpdated,
			Result:     stepCache.Result,
		}
	}

	return response
}

// GetSystemMetrics retrieves comprehensive system metrics
// GetSystemMetrics retrieves comprehensive system metrics
func (pm *ProcessManager) GetSystemMetrics() SystemMetrics {
	// Get queue stats
	queueStats := pm.GetQueueStats()

	// Get current system state
	pm.stateMu.RLock()
	systemState := *pm.state
	pm.stateMu.RUnlock()

	// Count total cache entries and active processes
	pm.mu.RLock()
	totalCacheEntries := len(pm.cache)
	activeProcesses := len(pm.progress)
	pm.mu.RUnlock()

	return SystemMetrics{
		TotalCacheEntries: totalCacheEntries,
		ActiveProcesses:   activeProcesses,
		QueueStats:        queueStats,
		SystemState:       systemState,
	}
}

```

]()